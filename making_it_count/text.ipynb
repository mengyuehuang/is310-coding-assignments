{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making it Coount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main assignment for this week is to try and discover:\n",
    "\n",
    "1. if there are any discourses that are distinctive of the early internet era versus the later web 2.0 era in the Humanist Listserv dataset.\n",
    "\n",
    "2. visualize such differnce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creidts to the professor: [https://drive.google.com/drive/folders/1zNTPmQm_HtR1zeCpRAp3XSDBsZuZq0U5?usp=sharing](https://drive.google.com/drive/folders/1zNTPmQm_HtR1zeCpRAp3XSDBsZuZq0U5?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume_text</th>\n",
       "      <th>volume_link</th>\n",
       "      <th>volume_dates</th>\n",
       "      <th>volume_number</th>\n",
       "      <th>inferred_start_year</th>\n",
       "      <th>inferred_end_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: MCCARTY@UTOREPAS\\nSubject: \\nDate: 12 Ma...</td>\n",
       "      <td>https://humanist.kdl.kcl.ac.uk/Archives/Conver...</td>\n",
       "      <td>1987-1988</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: Sebastian Rahtz \\nSubject: C++ and Gnu o...</td>\n",
       "      <td>https://humanist.kdl.kcl.ac.uk/Archives/Conver...</td>\n",
       "      <td>1988-1989</td>\n",
       "      <td>2</td>\n",
       "      <td>1988</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: Willard McCarty \\nSubject: Happy Birthda...</td>\n",
       "      <td>https://humanist.kdl.kcl.ac.uk/Archives/Conver...</td>\n",
       "      <td>1989-1990</td>\n",
       "      <td>3</td>\n",
       "      <td>1989</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: Elaine Brennan &amp; Allen Renear \\nSubject:...</td>\n",
       "      <td>https://humanist.kdl.kcl.ac.uk/Archives/Conver...</td>\n",
       "      <td>1990-1991</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Elaine Brennan &amp; Allen Renear \\nSubject:...</td>\n",
       "      <td>https://humanist.kdl.kcl.ac.uk/Archives/Conver...</td>\n",
       "      <td>1991-1992</td>\n",
       "      <td>5</td>\n",
       "      <td>1991</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         volume_text  \\\n",
       "0  From: MCCARTY@UTOREPAS\\nSubject: \\nDate: 12 Ma...   \n",
       "1  From: Sebastian Rahtz \\nSubject: C++ and Gnu o...   \n",
       "2  From: Willard McCarty \\nSubject: Happy Birthda...   \n",
       "3  From: Elaine Brennan & Allen Renear \\nSubject:...   \n",
       "4  From: Elaine Brennan & Allen Renear \\nSubject:...   \n",
       "\n",
       "                                         volume_link volume_dates  \\\n",
       "0  https://humanist.kdl.kcl.ac.uk/Archives/Conver...    1987-1988   \n",
       "1  https://humanist.kdl.kcl.ac.uk/Archives/Conver...    1988-1989   \n",
       "2  https://humanist.kdl.kcl.ac.uk/Archives/Conver...    1989-1990   \n",
       "3  https://humanist.kdl.kcl.ac.uk/Archives/Conver...    1990-1991   \n",
       "4  https://humanist.kdl.kcl.ac.uk/Archives/Conver...    1991-1992   \n",
       "\n",
       "   volume_number  inferred_start_year  inferred_end_year  \n",
       "0              1                 1987               1988  \n",
       "1              2                 1988               1989  \n",
       "2              3                 1989               1990  \n",
       "3              4                 1990               1991  \n",
       "4              5                 1991               1992  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humanist = pd.read_csv(r'C:\\Users\\98768\\Desktop\\is310\\making_it_count\\web_scraped_humanist_listserv_volumes.csv')\n",
    "humanist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Humanist Listserv dataset\n",
    "hu = pd.read_csv(r\"C:\\Users\\98768\\Desktop\\is310\\human-scraping\\humanist_listserv_volumes.csv\")\n",
    "pudding = pd.read_csv(\"categorized_pudding_public_scripts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volume Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volume 25/88-5/89</td>\n",
       "      <td>Humanist Archives Vol. 2 by subjectHumanist Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Volume 35/89-5/90</td>\n",
       "      <td>Humanist Archives Vol. 3  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Volume 45/90-5/91</td>\n",
       "      <td>Humanist Archives Vol. 4  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volume 55/91-5/92</td>\n",
       "      <td>Humanist Archives Vol. 5  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Volume 65/92-5/93</td>\n",
       "      <td>Humanist Archives Vol. 6  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Volume 75/93-5/94</td>\n",
       "      <td>Humanist Archives Vol. 7  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Volume 85/94-5/95</td>\n",
       "      <td>Humanist Archives Vol. 8  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Volume 95/95-5/96</td>\n",
       "      <td>Humanist Archives Vol. 9  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Volume 105/96-5/97</td>\n",
       "      <td>Humanist Archives Vol. 10  by subjectHumanist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Volume 115/97-5/98</td>\n",
       "      <td>Humanist.Archives.Vol.11 by subjectHumanist.Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Volume 125/98-5/99</td>\n",
       "      <td>Humanist.Archives.Vol.12 by subjectHumanist.Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Volume 135/99-5/00</td>\n",
       "      <td>Humanist.Archives.Vol.13: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Volume 145/00-5/01</td>\n",
       "      <td>Humanist.Archives.Vol.14: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Volume 155/01-5/02</td>\n",
       "      <td>Humanist.Archives.Vol.15: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Volume 165/02-5/03</td>\n",
       "      <td>Humanist.Archives.Vol.16: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Volume 175/03-5/04</td>\n",
       "      <td>\"Humanist: By Subject\"HumanistBy Subject826 me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Volume 185/04-5/05</td>\n",
       "      <td>\"Humanist: by subject\"Humanist by subject754 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Volume 195/05-5/06</td>\n",
       "      <td>Humanist Archives Vol. 19 : by subjectHumanist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Volume 205/06-5/07</td>\n",
       "      <td>Humanist Archives Vol. 20 : by subjectHumanist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Volume 215/07-2/08</td>\n",
       "      <td>Humanist Archives Vol. 21 : by subjectHumanist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Volume 25/88-5/89</td>\n",
       "      <td>Humanist Archives Vol. 2 by subjectHumanist Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Volume 35/89-5/90</td>\n",
       "      <td>Humanist Archives Vol. 3  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Volume 45/90-5/91</td>\n",
       "      <td>Humanist Archives Vol. 4  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Volume 55/91-5/92</td>\n",
       "      <td>Humanist Archives Vol. 5  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Volume 65/92-5/93</td>\n",
       "      <td>Humanist Archives Vol. 6  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Volume 75/93-5/94</td>\n",
       "      <td>Humanist Archives Vol. 7  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Volume 85/94-5/95</td>\n",
       "      <td>Humanist Archives Vol. 8  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Volume 95/95-5/96</td>\n",
       "      <td>Humanist Archives Vol. 9  by subjectHumanist A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Volume 105/96-5/97</td>\n",
       "      <td>Humanist Archives Vol. 10  by subjectHumanist ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Volume 115/97-5/98</td>\n",
       "      <td>Humanist.Archives.Vol.11 by subjectHumanist.Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Volume 125/98-5/99</td>\n",
       "      <td>Humanist.Archives.Vol.12 by subjectHumanist.Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Volume 135/99-5/00</td>\n",
       "      <td>Humanist.Archives.Vol.13: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Volume 145/00-5/01</td>\n",
       "      <td>Humanist.Archives.Vol.14: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Volume 155/01-5/02</td>\n",
       "      <td>Humanist.Archives.Vol.15: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Volume 165/02-5/03</td>\n",
       "      <td>Humanist.Archives.Vol.16: By SubjectHumanist.A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Volume 175/03-5/04</td>\n",
       "      <td>\"Humanist: By Subject\"HumanistBy Subject826 me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Volume 185/04-5/05</td>\n",
       "      <td>\"Humanist: by subject\"Humanist by subject754 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Volume 195/05-5/06</td>\n",
       "      <td>Humanist Archives Vol. 19 : by subjectHumanist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Volume 205/06-5/07</td>\n",
       "      <td>Humanist Archives Vol. 20 : by subjectHumanist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Volume 215/07-2/08</td>\n",
       "      <td>Humanist Archives Vol. 21 : by subjectHumanist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Volume                                        Volume Text\n",
       "0    Volume 25/88-5/89  Humanist Archives Vol. 2 by subjectHumanist Ar...\n",
       "1    Volume 35/89-5/90  Humanist Archives Vol. 3  by subjectHumanist A...\n",
       "2    Volume 45/90-5/91  Humanist Archives Vol. 4  by subjectHumanist A...\n",
       "3    Volume 55/91-5/92  Humanist Archives Vol. 5  by subjectHumanist A...\n",
       "4    Volume 65/92-5/93  Humanist Archives Vol. 6  by subjectHumanist A...\n",
       "5    Volume 75/93-5/94  Humanist Archives Vol. 7  by subjectHumanist A...\n",
       "6    Volume 85/94-5/95  Humanist Archives Vol. 8  by subjectHumanist A...\n",
       "7    Volume 95/95-5/96  Humanist Archives Vol. 9  by subjectHumanist A...\n",
       "8   Volume 105/96-5/97  Humanist Archives Vol. 10  by subjectHumanist ...\n",
       "9   Volume 115/97-5/98  Humanist.Archives.Vol.11 by subjectHumanist.Ar...\n",
       "10  Volume 125/98-5/99  Humanist.Archives.Vol.12 by subjectHumanist.Ar...\n",
       "11  Volume 135/99-5/00  Humanist.Archives.Vol.13: By SubjectHumanist.A...\n",
       "12  Volume 145/00-5/01  Humanist.Archives.Vol.14: By SubjectHumanist.A...\n",
       "13  Volume 155/01-5/02  Humanist.Archives.Vol.15: By SubjectHumanist.A...\n",
       "14  Volume 165/02-5/03  Humanist.Archives.Vol.16: By SubjectHumanist.A...\n",
       "15  Volume 175/03-5/04  \"Humanist: By Subject\"HumanistBy Subject826 me...\n",
       "16  Volume 185/04-5/05  \"Humanist: by subject\"Humanist by subject754 m...\n",
       "17  Volume 195/05-5/06  Humanist Archives Vol. 19 : by subjectHumanist...\n",
       "18  Volume 205/06-5/07  Humanist Archives Vol. 20 : by subjectHumanist...\n",
       "19  Volume 215/07-2/08  Humanist Archives Vol. 21 : by subjectHumanist...\n",
       "20   Volume 25/88-5/89  Humanist Archives Vol. 2 by subjectHumanist Ar...\n",
       "21   Volume 35/89-5/90  Humanist Archives Vol. 3  by subjectHumanist A...\n",
       "22   Volume 45/90-5/91  Humanist Archives Vol. 4  by subjectHumanist A...\n",
       "23   Volume 55/91-5/92  Humanist Archives Vol. 5  by subjectHumanist A...\n",
       "24   Volume 65/92-5/93  Humanist Archives Vol. 6  by subjectHumanist A...\n",
       "25   Volume 75/93-5/94  Humanist Archives Vol. 7  by subjectHumanist A...\n",
       "26   Volume 85/94-5/95  Humanist Archives Vol. 8  by subjectHumanist A...\n",
       "27   Volume 95/95-5/96  Humanist Archives Vol. 9  by subjectHumanist A...\n",
       "28  Volume 105/96-5/97  Humanist Archives Vol. 10  by subjectHumanist ...\n",
       "29  Volume 115/97-5/98  Humanist.Archives.Vol.11 by subjectHumanist.Ar...\n",
       "30  Volume 125/98-5/99  Humanist.Archives.Vol.12 by subjectHumanist.Ar...\n",
       "31  Volume 135/99-5/00  Humanist.Archives.Vol.13: By SubjectHumanist.A...\n",
       "32  Volume 145/00-5/01  Humanist.Archives.Vol.14: By SubjectHumanist.A...\n",
       "33  Volume 155/01-5/02  Humanist.Archives.Vol.15: By SubjectHumanist.A...\n",
       "34  Volume 165/02-5/03  Humanist.Archives.Vol.16: By SubjectHumanist.A...\n",
       "35  Volume 175/03-5/04  \"Humanist: By Subject\"HumanistBy Subject826 me...\n",
       "36  Volume 185/04-5/05  \"Humanist: by subject\"Humanist by subject754 m...\n",
       "37  Volume 195/05-5/06  Humanist Archives Vol. 19 : by subjectHumanist...\n",
       "38  Volume 205/06-5/07  Humanist Archives Vol. 20 : by subjectHumanist...\n",
       "39  Volume 215/07-2/08  Humanist Archives Vol. 21 : by subjectHumanist..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>script_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>gross_ia</th>\n",
       "      <th>link</th>\n",
       "      <th>status_code</th>\n",
       "      <th>script</th>\n",
       "      <th>script_length</th>\n",
       "      <th>predominant_character_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0023622</td>\n",
       "      <td>5154</td>\n",
       "      <td>Trouble in Paradise</td>\n",
       "      <td>1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.aellea.com/emruf3/tip.html</td>\n",
       "      <td>200.0</td>\n",
       "      <td>\\n\\n\\n\\nTrouble in Paradise\\n\\n\\nTrouble in Pa...</td>\n",
       "      <td>139460</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0024368</td>\n",
       "      <td>4677</td>\n",
       "      <td>Mystery of the Wax Museum</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.aellea.com/script/qWAX.htm</td>\n",
       "      <td>200.0</td>\n",
       "      <td>\\n\\n\\n\\nMystery of the Wax Museum \\n\\n\\tFADE I...</td>\n",
       "      <td>129951</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0025878</td>\n",
       "      <td>5115</td>\n",
       "      <td>The Thin Man</td>\n",
       "      <td>1934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.dailyscript.com/scripts/thethinman....</td>\n",
       "      <td>200.0</td>\n",
       "      <td>\\n\\n\\nTHE THIN MAN by Playback by Frances Good...</td>\n",
       "      <td>343532</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0025905</td>\n",
       "      <td>5147</td>\n",
       "      <td>Transatlantic Merry-Go-Round</td>\n",
       "      <td>1934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.aellea.com/emruf3/tm.html</td>\n",
       "      <td>200.0</td>\n",
       "      <td>\\n\\nTransatlantic Merry-Go-Round\\n\\n\\n\\nTransa...</td>\n",
       "      <td>211682</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0031679</td>\n",
       "      <td>4658</td>\n",
       "      <td>Mr. Smith Goes to Washington</td>\n",
       "      <td>1939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.dailyscript.com/scripts/Mr%20Smith%...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>\"MR. SMITH GOES ...</td>\n",
       "      <td>431648</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id  script_id                         title  year  gross_ia  \\\n",
       "0  tt0023622       5154           Trouble in Paradise  1932       NaN   \n",
       "1  tt0024368       4677     Mystery of the Wax Museum  1933       NaN   \n",
       "2  tt0025878       5115                  The Thin Man  1934       NaN   \n",
       "3  tt0025905       5147  Transatlantic Merry-Go-Round  1934       NaN   \n",
       "4  tt0031679       4658  Mr. Smith Goes to Washington  1939       NaN   \n",
       "\n",
       "                                                link  status_code  \\\n",
       "0              http://www.aellea.com/emruf3/tip.html        200.0   \n",
       "1              http://www.aellea.com/script/qWAX.htm        200.0   \n",
       "2  http://www.dailyscript.com/scripts/thethinman....        200.0   \n",
       "3               http://www.aellea.com/emruf3/tm.html        200.0   \n",
       "4  http://www.dailyscript.com/scripts/Mr%20Smith%...        200.0   \n",
       "\n",
       "                                              script  script_length  \\\n",
       "0  \\n\\n\\n\\nTrouble in Paradise\\n\\n\\nTrouble in Pa...         139460   \n",
       "1  \\n\\n\\n\\nMystery of the Wax Museum \\n\\n\\tFADE I...         129951   \n",
       "2  \\n\\n\\nTHE THIN MAN by Playback by Frances Good...         343532   \n",
       "3  \\n\\nTransatlantic Merry-Go-Round\\n\\n\\n\\nTransa...         211682   \n",
       "4                                \"MR. SMITH GOES ...         431648   \n",
       "\n",
       "  predominant_character_gender  \n",
       "0                            m  \n",
       "1                            m  \n",
       "2                            m  \n",
       "3                            m  \n",
       "4                            m  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pudding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code from our lesson in class. Try running it and see if you can understand what it does. Then, try to modify it to see if you can get different results. Use the documentation to help you understand what each parameter does [https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). In particular, try out the `max_df`, `min_df`, and `ngram_range` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our texts to a list\n",
    "documents = humanist.volume_text.tolist()\n",
    "\n",
    "#Create a vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=.8)\n",
    "# Fit the vectorizer to our documents\n",
    "transformed_documents = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Now get the top features for each document\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "\n",
    "# Get the dates for each volume\n",
    "dates = humanist.inferred_start_year.tolist()\n",
    "\n",
    "# Create an empty list to store our results\n",
    "tfidf_results = []\n",
    "\n",
    "# Loop through each document and get the top terms\n",
    "for counter, doc in enumerate(transformed_documents_as_array):\n",
    "    # Zip together the terms and the scores\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names_out(), doc))\n",
    "    # Sort the terms by score\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    # Add the date to the dataframe\n",
    "    one_doc_as_df['inferred_start_year'] = dates[counter]\n",
    "    # Append the dataframe to our list\n",
    "    tfidf_results.append(one_doc_as_df)\n",
    "# Concatenate all the dataframes together\n",
    "tfidf_df = pd.concat(tfidf_results)\n",
    "# Sort the dataframe by score\n",
    "tfidf_df = tfidf_df.sort_values(by=['score'], ascending=False)\n",
    "# Get the top ten terms for each year\n",
    "top_terms = tfidf_df.groupby('inferred_start_year').apply(lambda x: x.sort_values('score', ascending=False).head(10)).reset_index(drop=True)\n",
    "# Convert the inferred_start_year to a datetime\n",
    "top_terms['inferred_start_year'] = pd.to_datetime(top_terms['inferred_start_year'], format='%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = alt.selection_point(fields=['term'], bind='legend')\n",
    "chart = alt.Chart(top_terms).mark_bar().encode(\n",
    "    y='score',\n",
    "    x='inferred_start_year:T',\n",
    "    color=alt.Color('term', legend=alt.Legend(title='Term', orient='right', symbolLimit=len(top_terms['term'].unique()), columns=5), scale=alt.Scale(scheme='tableau20')),\n",
    "    tooltip=['term', 'score', 'year(inferred_start_year)'],\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    ").add_params(selection).properties(\n",
    "    title='Top 10 Terms by TF-IDF Score in Humanist Volumes'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodization of Humanist Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the volumes by period\n",
    "humanist['period'] = pd.cut(humanist['inferred_start_year'], bins=[float('-inf'), 2000, 2010, 2020], labels=['early_internet', 'web_2.0', 'contemporary'])\n",
    "# Create a vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=.8)\n",
    "# Fit the vectorizer to our documents\n",
    "transformed_documents = vectorizer.fit_transform(humanist.groupby('period')['volume_text'].apply(' '.join).tolist())\n",
    "# Now get the top features for each document\n",
    "transformed_documents_as_array = transformed_documents.toarray()\n",
    "# Get the periods for each volume\n",
    "periods = humanist['period'].unique()\n",
    "# Create an empty list to store our results\n",
    "tfidf_results = []\n",
    "# Loop through each document and get the top terms\n",
    "for counter, doc in enumerate(transformed_documents_as_array):\n",
    "    # Zip together the terms and the scores\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names_out(), doc))\n",
    "    # Sort the terms by score\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    # Add the date to the dataframe\n",
    "    one_doc_as_df['period'] = periods[counter]\n",
    "    # Append the dataframe to our list\n",
    "    tfidf_results.append(one_doc_as_df)\n",
    "# Concatenate all the dataframes together\n",
    "tfidf_df = pd.concat(tfidf_results)\n",
    "# Sort the dataframe by score\n",
    "tfidf_df = tfidf_df.sort_values(by=['score'], ascending=False)\n",
    "# Get the top thirty terms for each period\n",
    "top_terms = tfidf_df.groupby('period').apply(lambda x: x.sort_values('score', ascending=False).head(30)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_terms['period'] = top_terms['period'].astype(str)\n",
    "selection = alt.selection_point(fields=['term'], bind='legend')\n",
    "chart = alt.Chart(top_terms).mark_bar().encode(\n",
    "    y='score',\n",
    "    x=alt.X('period', sort=['early_internet', 'web_2.0', 'contemporary'], axis=alt.Axis(title='Period')),\n",
    "    color=alt.Color('term', legend=alt.Legend(title='Term', orient='right', symbolLimit=len(top_terms['term'].unique()), columns=5), scale=alt.Scale(scheme='tableau20')),\n",
    "    tooltip=['term', 'score', 'period'],\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    ").add_params(selection).properties(\n",
    "    title='Top 30 Terms by TF-IDF Score in Humanist Volumes by Period'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the code from our lesson in class. See if you can understand what it does. Then, try to modify it to see if you can get different results. Use the documentation to help you understand what each parameter does [https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html). In particular, try out the `n_components` and differing TF-IDF parameters. Also try using the pudding_data dataset to see if you can get different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "vectorizer = TfidfVectorizer(max_df=0.8)\n",
    "tfidf = vectorizer.fit_transform(humanist['volume_text'])\n",
    "\n",
    "# Perform topic modeling\n",
    "lda = LatentDirichletAllocation(n_components=len(humanist), max_iter=20, random_state=0)\n",
    "lda.fit(tfidf)\n",
    "\n",
    "# Get the top words for each topic\n",
    "top_words = vectorizer.get_feature_names_out()\n",
    "topic_words = {}\n",
    "for topic, comp in enumerate(lda.components_):\n",
    "    word_idx = np.argsort(comp)[::-1][:10]\n",
    "    topic_words[topic] = [top_words[i] for i in word_idx]\n",
    "\n",
    "# Print the top words for each topic\n",
    "for topic, words in topic_words.items():\n",
    "    print(f\"Topic #{topic}: {', '.join(words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out the code from our lesson in class. See if you can understand what it does. Then, try to modify it to see if you can get different results. Use the documentation to help you understand what each parameter does [https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). In particular, try out the TFIDF parameters. Also try using the `gender_category` in the pudding_data dataset to see if you can get different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.8)\n",
    "# Fit the vectorizer to our documents\n",
    "transformed_documents = vectorizer.fit_transform(humanist_vols['volume_text'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_documents, humanist_vols['period'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Train a logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the time period of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients for each term\n",
    "coefficients = clf.coef_\n",
    "# Get the terms\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "# Create a dataframe of the terms and coefficients\n",
    "terms_df = pd.DataFrame({'term': terms, 'contemporary': coefficients[0], 'early_internet': coefficients[1], 'web_2.0': coefficients[2]})\n",
    "# Get the top terms for each period\n",
    "top_terms = terms_df.melt(id_vars='term', var_name='period', value_name='coefficient').sort_values(by='coefficient', ascending=False).groupby('period').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize top terms\n",
    "top_terms['period'] = top_terms['period'].astype(str)\n",
    "selection = alt.selection_point(fields=['term'], bind='legend')\n",
    "\n",
    "# Define the sort order for the periods\n",
    "period_order = ['early_internet', 'web_2.0', 'contemporary']\n",
    "\n",
    "chart = alt.Chart(top_terms).mark_bar().encode(\n",
    "    x=alt.X('period', sort=['early_internet', 'web_2.0', 'contemporary'], axis=alt.Axis(title='Period')),\n",
    "    y=alt.Y('coefficient:Q'),  # Sort terms by score in descending order\n",
    "    color=alt.Color('term', legend=alt.Legend(title='Term', orient='right', symbolLimit=len(top_terms['term'].unique()), columns=5), scale=alt.Scale(scheme='tableau20')),\n",
    "    tooltip=['term', 'coefficient', 'period'],\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    ").add_params(selection).properties(\n",
    "    title='Top 10 Terms by Coefficient in Logistic Regression Model by Period'\n",
    ")\n",
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-work-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
